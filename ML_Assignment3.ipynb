{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhijeetkhade11/KaggleCompetitions/blob/main/ML_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKwNYqajQE3W"
      },
      "outputs": [],
      "source": [
        "pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "bank_marketing = fetch_ucirepo(id=222)\n",
        "\n",
        "X = bank_marketing.data.features.copy()\n",
        "y = bank_marketing.data.targets.copy()"
      ],
      "metadata": {
        "id": "QkrPJZecQIfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "y = y.squeeze()\n",
        "y = y.map({'no':0, 'yes':1})"
      ],
      "metadata": {
        "id": "gZK0Y41fW7Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "Ved1bsemQKj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "cnt6M-pgRzAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "id": "Pe4XMlFJR0jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = [\n",
        "    \"job\", \"education\", \"default\", \"housing\", \"loan\",\n",
        "    \"poutcome\", \"month\", \"contact\"\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    \"age\", \"balance\",\n",
        "    \"campaign\", \"pdays\", \"previous\",\n",
        "    \"duration\"\n",
        "]"
      ],
      "metadata": {
        "id": "WUIsCXA-TPf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[num_cols] = X[num_cols].fillna(X[num_cols].mean())\n",
        "\n",
        "for col in cat_cols:\n",
        "    X[col].fillna(X[col].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "TWoMcT_4UEzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "pA_dWcrXU3Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OrdinalEncoder(\n",
        "            handle_unknown=\"use_encoded_value\",\n",
        "            unknown_value=-1\n",
        "        ), cat_cols),\n",
        "\n",
        "        (\"num\", \"passthrough\", num_cols)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "5Z-chyeeTRPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_model = Pipeline([\n",
        "    (\"prep\", preprocess),\n",
        "    (\"clf\", LogisticRegression())\n",
        "])\n",
        "\n",
        "lr_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "BMCIwc7mTSzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = lr_model.predict(X_test)"
      ],
      "metadata": {
        "id": "ugqy2SSkV4sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall   :\", recall_score(y_test, y_pred))\n",
        "print(\"F1 Score :\", f1_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "_ircxaooTU7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = lr_model.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "id": "ChU2dQUYV7Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "auc_score = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "print(\"AUC Score:\", auc_score)"
      ],
      "metadata": {
        "id": "jZO_uddMWjeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.4f}\")\n",
        "plt.plot([0,1], [0,1], linestyle='--')\n",
        "\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_ZcQmUSWWpbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate_threshold(threshold):\n",
        "    y_pred = (y_prob >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    pre = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1  = f1_score(y_test, y_pred)\n",
        "\n",
        "    return acc, pre, rec, f1"
      ],
      "metadata": {
        "id": "Ydc6EWkKX42o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc1, pre1, rec1, f11 = evaluate_threshold(0.5)\n"
      ],
      "metadata": {
        "id": "ZIdANnw2ZPEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "thresholds = np.arange(0.1, 0.9, 0.01)\n",
        "\n",
        "best_thr = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred = (y_prob >= t).astype(int)\n",
        "    score = f1_score(y_test, y_pred)\n",
        "\n",
        "    if score > best_f1:\n",
        "        best_f1 = score\n",
        "        best_thr = t\n",
        "\n",
        "print(\"Best Threshold:\", best_thr)\n"
      ],
      "metadata": {
        "id": "LYWQVz-fZQeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc2, pre2, rec2, f12 = evaluate_threshold(best_thr)"
      ],
      "metadata": {
        "id": "VmDIvAXGZajk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nThreshold = 0.5\")\n",
        "print(\"Accuracy :\", acc1)\n",
        "print(\"Precision:\", pre1)\n",
        "print(\"Recall   :\", rec1)\n",
        "print(\"F1 Score :\", f11)\n",
        "\n",
        "print(\"\\nOptimized Threshold =\", best_thr)\n",
        "print(\"Accuracy :\", acc2)\n",
        "print(\"Precision:\", pre2)\n",
        "print(\"Recall   :\", rec2)\n",
        "print(\"F1 Score :\", f12)\n"
      ],
      "metadata": {
        "id": "edTAipRYZRxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Why is the ROC curve useful?\n",
        "\n",
        "ans. ROC shows how well the model separates classes across all thresholds by plotting TPR vs FPR, and AUC summarizes overall performance independent of any single threshold.\n",
        "\n",
        "Q2. What changes when the threshold changes (precisionâ€“recall trade-off)?\n",
        "\n",
        "ans. Lowering threshold increases recall but reduces precision (more positives detected but more false alarms), while increasing threshold increases precision but reduces recall (fewer false alarms but more missed positives).\n"
      ],
      "metadata": {
        "id": "hSyDj9EYZ9tq"
      }
    }
  ]
}